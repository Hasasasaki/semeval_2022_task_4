{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hasasasaki/semeval_2022_task_4/blob/main/model_finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n"
      ],
      "metadata": {
        "id": "4qHbOJcwcWcv"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv_mP3i6UrPj",
        "outputId": "77de45be-e22d-40a7-d262-a4912104b40c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deep_translator in /usr/local/lib/python3.11/dist-packages (1.11.4)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.11/dist-packages (from deep_translator) (4.13.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from deep_translator) (2.32.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "# !pip install \"flash_attn==2.6.3\" --no-build-isolation\n",
        "!pip install deep_translator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HglL0PQVLpR"
      },
      "source": [
        "## Data processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "4n7udvqWVLpS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    DataCollatorWithPadding,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    TrainerCallback,\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "import torch.nn as nn\n",
        "\n",
        "seed = 42\n",
        "\n",
        "def set_seed(seed=seed):\n",
        "    \"\"\"Set all seeds to make results reproducible\"\"\"\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "set_seed()\n",
        "\n",
        "new_columns = [\n",
        "    \"par_id\",      # 1 (integer ID)\n",
        "    \"art_id\",      # @@24942188 (article identifier)\n",
        "    \"topic\",       # hopeless (PCL category)\n",
        "    \"country\",     # ph (country code)\n",
        "    \"text\",        # Full text content\n",
        "    \"label\"        # 0 (binary label)\n",
        "]\n",
        "\n",
        "# Read main dataset - skip 4 disclaimer rows\n",
        "df = pd.read_csv(\n",
        "    \"data/dontpatronizeme_pcl.tsv\",\n",
        "    sep=\"\\t\",\n",
        "    header=None,\n",
        "    skiprows=4,\n",
        "    names=new_columns,\n",
        "    on_bad_lines='warn'\n",
        ")\n",
        "\n",
        "# Read train/dev splits\n",
        "train_val_labels = pd.read_csv(\"data/train_semeval_parids-labels.csv\")\n",
        "test_labels = pd.read_csv(\"data/dev_semeval_parids-labels.csv\")\n",
        "\n",
        "# Convert string labels to lists\n",
        "def parse_labels(label_str: str) -> list[int]:\n",
        "    return [int(x) for x in label_str.strip(\"[]\").replace(\" \", \"\").split(\",\")]\n",
        "\n",
        "# Process labels dataframes\n",
        "for labels_df in [train_val_labels, test_labels]:\n",
        "    labels_df['labels'] = labels_df['label'].apply(parse_labels)\n",
        "    labels_df.drop('label', axis=1, inplace=True)\n",
        "\n",
        "# Join with main data\n",
        "train_val_df = df.merge(train_val_labels, on=\"par_id\", how=\"inner\")\n",
        "test_df = df.merge(test_labels, on=\"par_id\", how=\"inner\")\n",
        "\n",
        "# Add PCL positivity column to both dataframes\n",
        "train_val_df['pcl_label'] = train_val_df['label'].apply(\n",
        "    lambda x: 0 if x in {0, 1} else 1)\n",
        "test_df['pcl_label'] = test_df['label'].apply(\n",
        "    lambda x: 0 if x in {0, 1} else 1)\n",
        "\n",
        "train_df, val_df = train_test_split(train_val_df, test_size=0.2, random_state=seed, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlPG3JxjUGWp",
        "outputId": "dd1685d9-2e46-4a18-efbb-fb230c2c2c5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "import nltk\n",
        "# os.environ[\"TRANSFORMERS_CACHE\"] = \"/vol/bitbucket/bj321/.cache\"\n",
        "# nltk.data.path.append(\"/vol/bitbucket/bj321/nltk_data\")  # Your custom path\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSIrXlbcUGWp",
        "outputId": "8ff38535-56fe-456c-9877-47d361ed0c19"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5779"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OzlLMoQUGWp",
        "outputId": "59bacef1-f2a3-4655-8563-316a5e1b2d0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading SentenceBERT model...\n"
          ]
        }
      ],
      "source": [
        "from deep_translator import GoogleTranslator\n",
        "import concurrent.futures\n",
        "import time\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# Load SentenceBERT model\n",
        "print(\"Loading SentenceBERT model...\")\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')  # Smaller, faster model\n",
        "# Alternative: model = SentenceTransformer('paraphrase-mpnet-base-v2')  # More accurate but slower\n",
        "\n",
        "def compute_similarity(original, translated):\n",
        "    \"\"\"Compute cosine similarity between original and translated text embeddings\"\"\"\n",
        "    # Get embeddings\n",
        "    emb1 = model.encode([original])[0]\n",
        "    emb2 = model.encode([translated])[0]\n",
        "\n",
        "    # Compute cosine similarity (1 - cosine distance)\n",
        "    similarity = 1 - cosine(emb1, emb2)\n",
        "    return similarity\n",
        "\n",
        "def back_translate_single(item):\n",
        "    \"\"\"Process a single text item with similarity filtering\"\"\"\n",
        "    text, label, par_id, source, target, idx, similarity_threshold = item\n",
        "    try:\n",
        "        # First translation (source to target)\n",
        "        translated = GoogleTranslator(source=source, target=target).translate(text)\n",
        "        time.sleep(0.5)  # Avoid rate limiting\n",
        "\n",
        "        # Second translation (target back to source)\n",
        "        back_translated = GoogleTranslator(source=target, target=source).translate(translated)\n",
        "\n",
        "        # Compute semantic similarity\n",
        "        similarity = compute_similarity(text, back_translated)\n",
        "\n",
        "        # Only return translations that maintain semantic similarity\n",
        "        if similarity >= similarity_threshold:\n",
        "            return back_translated, label, par_id, idx, similarity, True\n",
        "        else:\n",
        "            print(f\"Low similarity ({similarity:.3f}) for item {idx}: discarded\")\n",
        "            return text, label, par_id, idx, similarity, False  # Return original text but mark as not augmented\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in item {idx}: {str(e)}\")\n",
        "        return None, None, None, idx, 0.0, False\n",
        "\n",
        "def back_translate_batch(texts, labels, par_ids, source='en', target='zh-CN', max_workers=5, similarity_threshold=0.75):\n",
        "    \"\"\"Process texts in parallel batches with similarity filtering\"\"\"\n",
        "    results = [None] * len(texts)\n",
        "    labels_out = [None] * len(labels)\n",
        "    par_ids_out = [None] * len(par_ids)\n",
        "    similarities = [0.0] * len(texts)\n",
        "    is_augmented = [False] * len(texts)\n",
        "\n",
        "    # Create work items\n",
        "    work_items = [(texts[i], labels[i], par_ids[i], source, target, i, similarity_threshold) for i in range(len(texts))]\n",
        "\n",
        "    # Process in parallel\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        futures = [executor.submit(back_translate_single, item) for item in work_items]\n",
        "\n",
        "        # Process results as they complete\n",
        "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures)):\n",
        "            result, label, par_id, idx, similarity, augmented = future.result()\n",
        "            if result is not None:\n",
        "                results[idx] = result\n",
        "                labels_out[idx] = label\n",
        "                par_ids_out[idx] = par_id\n",
        "                similarities[idx] = similarity\n",
        "                is_augmented[idx] = augmented\n",
        "\n",
        "    # Create DataFrame with results\n",
        "    result_df = pd.DataFrame({\n",
        "        'par_id': par_ids_out,\n",
        "        'original_text': texts,\n",
        "        'text': results,\n",
        "        'pcl_label': [int(x) for x in labels_out if x is not None else None],\n",
        "        'similarity': similarities,\n",
        "        'is_augmented': is_augmented\n",
        "    })\n",
        "\n",
        "    # Filter out None values\n",
        "    result_df = result_df.dropna(subset=['text'])\n",
        "\n",
        "    return result_df\n",
        "\n",
        "# Main processing loop\n",
        "language_list = ['zh-CN', 'fr', 'de', 'es', 'ru']\n",
        "similarity_threshold = 0.75  # Adjust as needed\n",
        "\n",
        "for language in language_list:\n",
        "    output_file = f'data/backtrans_data_{language}.csv'\n",
        "\n",
        "    if not os.path.exists(output_file):\n",
        "        print(f\"Processing language: {language}\")\n",
        "\n",
        "        # Process in chunks to avoid memory issues\n",
        "        chunk_size = 100\n",
        "        all_results_df = pd.DataFrame()\n",
        "\n",
        "        for i in range(0, len(train_df), chunk_size):\n",
        "            chunk_texts = train_df['text'].iloc[i:i+chunk_size].tolist()\n",
        "            chunk_labels = train_df['pcl_label'].iloc[i:i+chunk_size].tolist()\n",
        "            chunk_par_ids = train_df['par_id'].iloc[i:i+chunk_size].tolist()\n",
        "\n",
        "            print(f\"Processing chunk {i//chunk_size + 1}/{len(train_df)//chunk_size + 1}\")\n",
        "            result_df = back_translate_batch(\n",
        "                chunk_texts,\n",
        "                chunk_labels,\n",
        "                chunk_par_ids,\n",
        "                source='en',\n",
        "                target=language,\n",
        "                max_workers=5,\n",
        "                similarity_threshold=similarity_threshold\n",
        "            )\n",
        "\n",
        "            all_results_df = pd.concat([all_results_df, result_df])\n",
        "\n",
        "            # Save intermediate results\n",
        "            all_results_df.to_csv(f'data/backtrans_temp_{language}.csv', index=False)\n",
        "\n",
        "            # Optional: Add a delay between chunks\n",
        "            time.sleep(2)\n",
        "\n",
        "        # Save final results\n",
        "        all_results_df.to_csv(output_file, index=False)\n",
        "\n",
        "        # Print statistics\n",
        "        total = len(all_results_df)\n",
        "        augmented = all_results_df['is_augmented'].sum()\n",
        "        print(f\"Completed {language}: {total} samples processed\")\n",
        "        print(f\"Kept {augmented} samples ({augmented/total:.1%}) with similarity ≥ {similarity_threshold}\")\n",
        "        print(f\"Average similarity: {all_results_df['similarity'].mean():.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCa0qvJqVLpT"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "-mKaqTS0VLpT"
      },
      "outputs": [],
      "source": [
        "\n",
        "batch_size = 16\n",
        "lr = 8e-5\n",
        "n_epochs = 2\n",
        "betas = (0.9, 0.98)\n",
        "eps = 1e-6\n",
        "wd = 1e-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "0oXKJCEbVLpT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8465fc6-24cb-48d4-bc23-01cba8ef39a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded data/backtrans_data_de.csv with 10468 rows\n",
            "Loaded data/backtrans_data_es.csv with 10468 rows\n",
            "Loaded data/backtrans_data_fr.csv with 10468 rows\n",
            "Loaded data/backtrans_data_zh-CN.csv with 10468 rows\n",
            "Combined backtranslation data: 21793 rows\n",
            "   par_id art_id topic country  \\\n",
            "0     NaN   None  None    None   \n",
            "1     NaN   None  None    None   \n",
            "2     NaN   None  None    None   \n",
            "3     NaN   None  None    None   \n",
            "4     NaN   None  None    None   \n",
            "\n",
            "                                                text label labels  pcl_label  \n",
            "0  It described the local police as under resourc...  None   None          0  \n",
            "1  The only force that is able to stop it is the ...  None   None          1  \n",
            "2  The government's plans to return to mass finan...  None   None          0  \n",
            "3  New figures show that more than 48,000 Rohingy...  None   None          0  \n",
            "4  He then listed several immigrants, mainly from...  None   None          0  \n"
          ]
        }
      ],
      "source": [
        "class PCLDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, balance_method='oversample', seed=seed):\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "         # Split into positive and negative classes\n",
        "        pos_df = dataframe[dataframe['pcl_label'] == 1]\n",
        "        neg_df = dataframe[dataframe['pcl_label'] == 0]\n",
        "\n",
        "        # Balance classes\n",
        "        if balance_method == 'oversample':\n",
        "            # Repeat minority class samples\n",
        "            if len(pos_df) > len(neg_df):\n",
        "                pos_df, neg_df = neg_df, pos_df\n",
        "            n_samples = max(len(pos_df), len(neg_df))\n",
        "            pos_df = pos_df.sample(n_samples, replace=True, random_state=seed)\n",
        "        elif balance_method == 'undersample':\n",
        "            # Take minimum number of samples\n",
        "            n_samples = min(len(pos_df), len(neg_df))\n",
        "            pos_df = pos_df.sample(n_samples, random_state=seed)\n",
        "            neg_df = neg_df.sample(n_samples, random_state=seed)\n",
        "        elif balance_method == 'None':\n",
        "            pass\n",
        "\n",
        "        # Combine and shuffle\n",
        "        balanced_df = pd.concat([pos_df, neg_df]).sample(frac=1, random_state=seed)\n",
        "        self.texts = balanced_df['text'].tolist()\n",
        "        self.labels = balanced_df['pcl_label'].tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Initialize tokenizer and datasets\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"answerdotai/ModernBERT-base\")\n",
        "\n",
        "# Load all backtranslation files and combine them\n",
        "backtrans_files = [\n",
        "    'data/backtrans_data_de.csv',\n",
        "    'data/backtrans_data_es.csv',\n",
        "    'data/backtrans_data_fr.csv',\n",
        "    # 'data/backtrans_data_ru.csv',\n",
        "    'data/backtrans_data_zh-CN.csv'\n",
        "]\n",
        "\n",
        "backtrans_dfs = []\n",
        "for file in backtrans_files:\n",
        "    try:\n",
        "        cur_df = pd.read_csv(file)\n",
        "        backtrans_dfs.append(cur_df)\n",
        "        print(f\"Loaded {file} with {len(df)} rows\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {file}: {e}\")\n",
        "\n",
        "# Combine all backtranslation dataframes\n",
        "if backtrans_dfs:\n",
        "    backtrans_df = pd.concat(backtrans_dfs, ignore_index=True)\n",
        "    print(f\"Combined backtranslation data: {len(backtrans_df)} rows\")\n",
        "else:\n",
        "    backtrans_df = pd.DataFrame()\n",
        "    print(\"No backtranslation data found\")\n",
        "\n",
        "# Create datasets\n",
        "for col in train_df.columns:\n",
        "    if col not in backtrans_df.columns:\n",
        "        backtrans_df[col] = None\n",
        "\n",
        "backtrans_df = backtrans_df[train_df.columns]\n",
        "backtrans_df['pcl_label'] = backtrans_df['pcl_label'].astype(int)\n",
        "augmented_train_df = pd.concat([backtrans_df, train_df], ignore_index=True)\n",
        "print(augmented_train_df.head())\n",
        "train_dataset = PCLDataset(augmented_train_df, tokenizer)\n",
        "val_dataset = PCLDataset(val_df, tokenizer, balance_method='None')\n",
        "test_dataset = PCLDataset(test_df, tokenizer, balance_method='None')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ovyIzdKUGWq"
      },
      "source": [
        "## Weighted Random Sampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "cozqcQtdUGWq"
      },
      "outputs": [],
      "source": [
        "class WeightedRandomSamplerTrainer(Trainer):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.weights = torch.FloatTensor(self._get_weights())\n",
        "        self.sampler = WeightedRandomSampler(self.weights, len(self.weights), replacement=True)\n",
        "\n",
        "    def get_train_dataloader(self):\n",
        "        return DataLoader(self.train_dataset, batch_size=self.args.train_batch_size, sampler=self.sampler, collate_fn=self.data_collator)\n",
        "\n",
        "    def _get_weights(self):\n",
        "        labels = np.array(self.train_dataset.labels)\n",
        "        class_counts = np.bincount(labels)\n",
        "        class_weights = 1.0 / np.sqrt(class_counts.astype(np.float32))\n",
        "        weights = class_weights[labels]\n",
        "        return weights\n",
        "\n",
        "train_dataset = PCLDataset(augmented_train_df, tokenizer, 'None')\n",
        "val_dataset = PCLDataset(val_df, tokenizer, balance_method='None')\n",
        "test_dataset = PCLDataset(test_df, tokenizer, balance_method='None')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "aBn4QsCRVLpT",
        "outputId": "dc791d6f-b9df-4470-dc43-0d061349df61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3562' max='3562' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3562/3562 07:57, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.205700</td>\n",
              "      <td>0.469438</td>\n",
              "      <td>0.916418</td>\n",
              "      <td>0.530201</td>\n",
              "      <td>0.612403</td>\n",
              "      <td>0.467456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.015500</td>\n",
              "      <td>0.783807</td>\n",
              "      <td>0.920000</td>\n",
              "      <td>0.446281</td>\n",
              "      <td>0.739726</td>\n",
              "      <td>0.319527</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
              "0      0.2057         0.705695             0.000047          1.0   0.469438   \n",
              "1      0.0155         0.000129             0.000000          2.0   0.783807   \n",
              "\n",
              "   eval_accuracy   eval_f1  eval_precision  eval_recall  \n",
              "0       0.916418  0.530201        0.612403     0.467456  \n",
              "1       0.920000  0.446281        0.739726     0.319527  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a55c38dd-f5fb-40d3-9090-02f574000d03\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train_loss</th>\n",
              "      <th>train_grad_norm</th>\n",
              "      <th>train_learning_rate</th>\n",
              "      <th>train_epoch</th>\n",
              "      <th>eval_loss</th>\n",
              "      <th>eval_accuracy</th>\n",
              "      <th>eval_f1</th>\n",
              "      <th>eval_precision</th>\n",
              "      <th>eval_recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.2057</td>\n",
              "      <td>0.705695</td>\n",
              "      <td>0.000047</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.469438</td>\n",
              "      <td>0.916418</td>\n",
              "      <td>0.530201</td>\n",
              "      <td>0.612403</td>\n",
              "      <td>0.467456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0155</td>\n",
              "      <td>0.000129</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.783807</td>\n",
              "      <td>0.920000</td>\n",
              "      <td>0.446281</td>\n",
              "      <td>0.739726</td>\n",
              "      <td>0.319527</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a55c38dd-f5fb-40d3-9090-02f574000d03')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a55c38dd-f5fb-40d3-9090-02f574000d03 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a55c38dd-f5fb-40d3-9090-02f574000d03');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5d9758fc-9cbc-4ccb-a487-44e7484c7b20\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5d9758fc-9cbc-4ccb-a487-44e7484c7b20')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5d9758fc-9cbc-4ccb-a487-44e7484c7b20 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_89ab8cfe-2220-450c-b49b-9e261bdf66a2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_res_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_89ab8cfe-2220-450c-b49b-9e261bdf66a2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_res_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_res_df",
              "summary": "{\n  \"name\": \"train_res_df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"train_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13449170978168132,\n        \"min\": 0.0155,\n        \"max\": 0.2057,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0155,\n          0.2057\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_grad_norm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4989105624569206,\n        \"min\": 0.00012906844494864345,\n        \"max\": 0.7056951522827148,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.00012906844494864345,\n          0.7056951522827148\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_learning_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.320791782777752e-05,\n        \"min\": 0.0,\n        \"max\": 4.696308777021426e-05,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          4.696308777021426e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7071067811865476,\n        \"min\": 1.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2222924678495522,\n        \"min\": 0.4694375991821289,\n        \"max\": 0.7838066220283508,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.7838066220283508,\n          0.4694375991821289\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.002532919813205554,\n        \"min\": 0.9164179104477612,\n        \"max\": 0.92,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.92,\n          0.9164179104477612\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05934064895087062,\n        \"min\": 0.4462809917355372,\n        \"max\": 0.5302013422818792,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.4462809917355372,\n          0.5302013422818792\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0900309048149804,\n        \"min\": 0.6124031007751938,\n        \"max\": 0.7397260273972602,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.7397260273972602,\n          0.6124031007751938\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10460159485008098,\n        \"min\": 0.31952662721893493,\n        \"max\": 0.46745562130177515,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.31952662721893493,\n          0.46745562130177515\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          output_dir  overwrite_output_dir  do_train  do_eval  do_predict  \\\n",
              "0  ModernBERT_pcl_ft                 False     False     True       False   \n",
              "\n",
              "  eval_strategy  prediction_loss_only  per_device_train_batch_size  \\\n",
              "0         epoch                 False                           16   \n",
              "\n",
              "   per_device_eval_batch_size per_gpu_train_batch_size  ... split_batches  \\\n",
              "0                          16                     None  ...          None   \n",
              "\n",
              "   include_tokens_per_second include_num_input_tokens_seen  \\\n",
              "0                      False                         False   \n",
              "\n",
              "   neftune_noise_alpha optim_target_modules  batch_eval_metrics  \\\n",
              "0                 None                 None               False   \n",
              "\n",
              "   eval_on_start  use_liger_kernel  eval_use_gather_object  \\\n",
              "0          False             False                   False   \n",
              "\n",
              "   average_tokens_across_devices  \n",
              "0                          False  \n",
              "\n",
              "[1 rows x 131 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6185188c-6d4b-492b-a2d6-b0edd324459e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>output_dir</th>\n",
              "      <th>overwrite_output_dir</th>\n",
              "      <th>do_train</th>\n",
              "      <th>do_eval</th>\n",
              "      <th>do_predict</th>\n",
              "      <th>eval_strategy</th>\n",
              "      <th>prediction_loss_only</th>\n",
              "      <th>per_device_train_batch_size</th>\n",
              "      <th>per_device_eval_batch_size</th>\n",
              "      <th>per_gpu_train_batch_size</th>\n",
              "      <th>...</th>\n",
              "      <th>split_batches</th>\n",
              "      <th>include_tokens_per_second</th>\n",
              "      <th>include_num_input_tokens_seen</th>\n",
              "      <th>neftune_noise_alpha</th>\n",
              "      <th>optim_target_modules</th>\n",
              "      <th>batch_eval_metrics</th>\n",
              "      <th>eval_on_start</th>\n",
              "      <th>use_liger_kernel</th>\n",
              "      <th>eval_use_gather_object</th>\n",
              "      <th>average_tokens_across_devices</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ModernBERT_pcl_ft</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>epoch</td>\n",
              "      <td>False</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 131 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6185188c-6d4b-492b-a2d6-b0edd324459e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6185188c-6d4b-492b-a2d6-b0edd324459e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6185188c-6d4b-492b-a2d6-b0edd324459e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_f015c1c7-6f31-4826-bfeb-eca3927fa1e9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('args_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f015c1c7-6f31-4826-bfeb-eca3927fa1e9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('args_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "args_df"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_config = AutoConfig.from_pretrained(\"answerdotai/ModernBERT-base\")\n",
        "model_config.mlp_dropout = 0.2\n",
        "model_config.num_labels = 2\n",
        "\n",
        "# Initialize model with classification head\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"answerdotai/ModernBERT-base\",\n",
        "    num_labels=2,\n",
        ")\n",
        "model.train()\n",
        "# Training setup\n",
        "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# print(\"Using device:\", device)\n",
        "# model.to(device)\n",
        "training_args = TrainingArguments(\n",
        "    seed=seed,\n",
        "    data_seed=seed,\n",
        "    dataloader_num_workers=0,\n",
        "    output_dir=f\"ModernBERT_pcl_ft\",\n",
        "    learning_rate=lr,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=n_epochs,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    optim=\"adamw_torch_fused\",\n",
        "    adam_beta1=betas[0],\n",
        "    adam_beta2=betas[1],\n",
        "    adam_epsilon=eps,\n",
        "    # weight_decay=wd,\n",
        "    logging_strategy=\"epoch\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    bf16=True,\n",
        "    bf16_full_eval=True,\n",
        "    push_to_hub=False,\n",
        "    warmup_ratio=0.1,\n",
        "    full_determinism=True\n",
        "\n",
        ")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Calculate classification metrics for Hugging Face Trainer\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        labels, predictions, average='binary'\n",
        "    )\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "class MetricsCallback(TrainerCallback):\n",
        "    def __init__(self):\n",
        "        self.training_history = {\"train\": [], \"eval\": []}\n",
        "\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        if logs is not None:\n",
        "            if \"loss\" in logs:  # Training logs\n",
        "                self.training_history[\"train\"].append(logs)\n",
        "            elif \"eval_loss\" in logs:  # Evaluation logs\n",
        "                self.training_history[\"eval\"].append(logs)\n",
        "\n",
        "trainer = WeightedRandomSamplerTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    processing_class=tokenizer,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "metrics_callback = MetricsCallback()\n",
        "trainer.add_callback(metrics_callback)\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "train_history_df = pd.DataFrame(metrics_callback.training_history[\"train\"])\n",
        "train_history_df = train_history_df.add_prefix(\"train_\")\n",
        "eval_history_df = pd.DataFrame(metrics_callback.training_history[\"eval\"])\n",
        "train_res_df = pd.concat([train_history_df, eval_history_df], axis=1)\n",
        "\n",
        "args_df = pd.DataFrame([training_args.to_dict()])\n",
        "\n",
        "display(train_res_df)\n",
        "display(args_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKS9Ma6aVLpT"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "jO_h-VE7VLpT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0628610c-a8c9-4b75-b0a5-3b3adb4884e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   par_id      art_id      topic country  \\\n",
            "0       1  @@24942188   hopeless      ph   \n",
            "1       2  @@21968160    migrant      gh   \n",
            "2       3  @@16584954  immigrant      ie   \n",
            "3       4   @@7811231   disabled      nz   \n",
            "4       5   @@1494111    refugee      ca   \n",
            "\n",
            "                                                text  label  \n",
            "0  We 're living in times of absolute insanity , ...      0  \n",
            "1  In Libya today , there are countless number of...      0  \n",
            "2  White House press secretary Sean Spicer said t...      0  \n",
            "3  Council customers only signs would be displaye...      0  \n",
            "4  \" Just like we received migrants fleeing El Sa...      0  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-57-872016444787>:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(logits).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.7578843e-04, 9.9962413e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "checkpoint_path = \"./ModernBERT_pcl_ft/checkpoint-1781\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint_path)\n",
        "\n",
        "\n",
        "# Evaluation on a single example\n",
        "def predict_single(text: str, model, tokenizer, device='cuda'):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    encoding = tokenizer(\n",
        "        text,\n",
        "        max_length=512,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "\n",
        "    return F.softmax(logits).cpu().numpy()\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "test_input = df[df['label'] == 3]['text'].iloc[3]\n",
        "predict_single(test_input, model, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "Eizio0pSVLpU"
      },
      "outputs": [],
      "source": [
        "# from huggingface_hub import notebook_login\n",
        "\n",
        "# notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "B7IGhWHPyjpU"
      },
      "outputs": [],
      "source": [
        "# model_name = \"Hasasasaki/modernBERT_pcl_ft\"\n",
        "# model.push_to_hub(model_name)\n",
        "# tokenizer.push_to_hub(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "riUan1skzH_P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "93785250-d918-4ee3-fe6d-2fafee7841a1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='131' max='131' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [131/131 00:06]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.5408523082733154,\n",
              " 'eval_model_preparation_time': 0.0033,\n",
              " 'eval_accuracy': 0.9120879120879121,\n",
              " 'eval_f1': 0.5157894736842106,\n",
              " 'eval_precision': 0.5414364640883977,\n",
              " 'eval_recall': 0.49246231155778897,\n",
              " 'eval_runtime': 6.9616,\n",
              " 'eval_samples_per_second': 300.648,\n",
              " 'eval_steps_per_second': 18.817}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    processing_class=tokenizer,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "trainer.evaluate(test_dataset)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}