{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hasasasaki/semeval_2022_task_4/blob/main/model_finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "4qHbOJcwcWcv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv_mP3i6UrPj",
        "outputId": "136a9e55-b713-4155-a287-51042be7b823"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deep_translator in /usr/local/lib/python3.11/dist-packages (1.11.4)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.11/dist-packages (from deep_translator) (4.13.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from deep_translator) (2.32.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "# !pip install \"flash_attn==2.6.3\" --no-build-isolation\n",
        "!pip install deep_translator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HglL0PQVLpR"
      },
      "source": [
        "## Data processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "4n7udvqWVLpS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "47869938-6509-43ec-b901-f265ba347ad3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: an illegal memory access was encountered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-146-11ee541af53b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"All random states have been reset with seed {seed}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mreset_seeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m new_columns = [\n",
            "\u001b[0;32m<ipython-input-146-11ee541af53b>\u001b[0m in \u001b[0;36mreset_seeds\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreset_seeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py\u001b[0m in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    190\u001b[0m     \"\"\"\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_emptyCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    DataCollatorWithPadding,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    TrainerCallback,\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from collections import Counter\n",
        "\n",
        "seed = 42\n",
        "\n",
        "def reset_seeds(seed=seed):\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "    import numpy as np\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.use_deterministic_algorithms(True)\n",
        "\n",
        "    print(f\"All random states have been reset with seed {seed}\")\n",
        "\n",
        "reset_seeds()\n",
        "\n",
        "new_columns = [\n",
        "    \"par_id\",      # 1 (integer ID)\n",
        "    \"art_id\",      # @@24942188 (article identifier)\n",
        "    \"topic\",       # hopeless (PCL category)\n",
        "    \"country\",     # ph (country code)\n",
        "    \"text\",        # Full text content\n",
        "    \"label\"        # 0 (binary label)\n",
        "]\n",
        "\n",
        "# Read main dataset - skip 4 disclaimer rows\n",
        "df = pd.read_csv(\n",
        "    \"data/dontpatronizeme_pcl.tsv\",\n",
        "    sep=\"\\t\",\n",
        "    header=None,\n",
        "    skiprows=4,\n",
        "    names=new_columns,\n",
        "    on_bad_lines='warn'\n",
        ")\n",
        "\n",
        "# Read train/dev splits\n",
        "train_val_labels = pd.read_csv(\"data/train_semeval_parids-labels.csv\")\n",
        "test_labels = pd.read_csv(\"data/dev_semeval_parids-labels.csv\")\n",
        "\n",
        "# Convert string labels to lists\n",
        "def parse_labels(label_str: str) -> list[int]:\n",
        "    return [int(x) for x in label_str.strip(\"[]\").replace(\" \", \"\").split(\",\")]\n",
        "\n",
        "# Process labels dataframes\n",
        "for labels_df in [train_val_labels, test_labels]:\n",
        "    labels_df['labels'] = labels_df['label'].apply(parse_labels)\n",
        "    labels_df.drop('label', axis=1, inplace=True)\n",
        "\n",
        "# Join with main data\n",
        "train_val_df = df.merge(train_val_labels, on=\"par_id\", how=\"inner\")\n",
        "test_df = df.merge(test_labels, on=\"par_id\", how=\"inner\")\n",
        "\n",
        "# Add PCL positivity column to both dataframes\n",
        "train_val_df['pcl_label'] = train_val_df['label'].apply(\n",
        "    lambda x: 0 if x in {0, 1} else 1)\n",
        "test_df['pcl_label'] = test_df['label'].apply(\n",
        "    lambda x: 0 if x in {0, 1} else 1)\n",
        "\n",
        "train_df, val_df = train_test_split(train_val_df, test_size=0.2, random_state=42, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlPG3JxjUGWp"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "# os.environ[\"TRANSFORMERS_CACHE\"] = \"/vol/bitbucket/bj321/.cache\"\n",
        "# nltk.data.path.append(\"/vol/bitbucket/bj321/nltk_data\")  # Your custom path\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "VSIrXlbcUGWp",
        "outputId": "30c48ec2-c4fc-47d9-d91f-bde042ff18de"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: an illegal memory access was encountered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-143-0c934370c873>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/memory.py\u001b[0m in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    190\u001b[0m     \"\"\"\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_emptyCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OzlLMoQUGWp"
      },
      "outputs": [],
      "source": [
        "from deep_translator import GoogleTranslator\n",
        "import concurrent.futures\n",
        "import time\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# Load SentenceBERT model\n",
        "print(\"Loading SentenceBERT model...\")\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')  # Smaller, faster model\n",
        "# Alternative: model = SentenceTransformer('paraphrase-mpnet-base-v2')  # More accurate but slower\n",
        "\n",
        "def compute_similarity(original, translated):\n",
        "    \"\"\"Compute cosine similarity between original and translated text embeddings\"\"\"\n",
        "    # Get embeddings\n",
        "    emb1 = model.encode([original])[0]\n",
        "    emb2 = model.encode([translated])[0]\n",
        "\n",
        "    # Compute cosine similarity (1 - cosine distance)\n",
        "    similarity = 1 - cosine(emb1, emb2)\n",
        "    return similarity\n",
        "\n",
        "def back_translate_single(item):\n",
        "    \"\"\"Process a single text item with similarity filtering\"\"\"\n",
        "    text, label, par_id, source, target, idx, similarity_threshold = item\n",
        "    try:\n",
        "        # First translation (source to target)\n",
        "        translated = GoogleTranslator(source=source, target=target).translate(text)\n",
        "        time.sleep(0.5)  # Avoid rate limiting\n",
        "\n",
        "        # Second translation (target back to source)\n",
        "        back_translated = GoogleTranslator(source=target, target=source).translate(translated)\n",
        "\n",
        "        # Compute semantic similarity\n",
        "        similarity = compute_similarity(text, back_translated)\n",
        "\n",
        "        # Only return translations that maintain semantic similarity\n",
        "        if similarity >= similarity_threshold:\n",
        "            return back_translated, label, par_id, idx, similarity, True\n",
        "        else:\n",
        "            print(f\"Low similarity ({similarity:.3f}) for item {idx}: discarded\")\n",
        "            return text, label, par_id, idx, similarity, False  # Return original text but mark as not augmented\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in item {idx}: {str(e)}\")\n",
        "        return None, None, None, idx, 0.0, False\n",
        "\n",
        "def back_translate_batch(texts, labels, par_ids, source='en', target='zh-CN', max_workers=5, similarity_threshold=0.75):\n",
        "    \"\"\"Process texts in parallel batches with similarity filtering\"\"\"\n",
        "    results = [None] * len(texts)\n",
        "    labels_out = [None] * len(labels)\n",
        "    par_ids_out = [None] * len(par_ids)\n",
        "    similarities = [0.0] * len(texts)\n",
        "    is_augmented = [False] * len(texts)\n",
        "\n",
        "    # Create work items\n",
        "    work_items = [(texts[i], labels[i], par_ids[i], source, target, i, similarity_threshold) for i in range(len(texts))]\n",
        "\n",
        "    # Process in parallel\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        futures = [executor.submit(back_translate_single, item) for item in work_items]\n",
        "\n",
        "        # Process results as they complete\n",
        "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures)):\n",
        "            result, label, par_id, idx, similarity, augmented = future.result()\n",
        "            if result is not None:\n",
        "                results[idx] = result\n",
        "                labels_out[idx] = label\n",
        "                par_ids_out[idx] = par_id\n",
        "                similarities[idx] = similarity\n",
        "                is_augmented[idx] = augmented\n",
        "\n",
        "    # Create DataFrame with results\n",
        "    result_df = pd.DataFrame({\n",
        "        'par_id': par_ids_out,\n",
        "        'original_text': texts,\n",
        "        'text': results,\n",
        "        'pcl_label': [int(x) if x is not None else None for x in labels_out],\n",
        "        'similarity': similarities,\n",
        "        'is_augmented': is_augmented\n",
        "    })\n",
        "\n",
        "    # Filter out None values\n",
        "    result_df = result_df.dropna(subset=['text'])\n",
        "\n",
        "    return result_df\n",
        "\n",
        "# Main processing loop\n",
        "language_list = ['zh-CN', 'fr', 'ru']\n",
        "similarity_threshold = 0.75  # Adjust as needed\n",
        "\n",
        "for language in language_list:\n",
        "    output_file = f'data/backtrans_data_{language}.csv'\n",
        "\n",
        "    if not os.path.exists(output_file):\n",
        "        print(f\"Processing language: {language}\")\n",
        "\n",
        "        # Process in chunks to avoid memory issues\n",
        "        chunk_size = 100\n",
        "        all_results_df = pd.DataFrame()\n",
        "\n",
        "        for i in range(0, len(train_df), chunk_size):\n",
        "            chunk_texts = train_df['text'].iloc[i:i+chunk_size].tolist()\n",
        "            chunk_labels = train_df['pcl_label'].iloc[i:i+chunk_size].tolist()\n",
        "            chunk_par_ids = train_df['par_id'].iloc[i:i+chunk_size].tolist()\n",
        "\n",
        "            print(f\"Processing chunk {i//chunk_size + 1}/{len(train_df)//chunk_size + 1}\")\n",
        "            result_df = back_translate_batch(\n",
        "                chunk_texts,\n",
        "                chunk_labels,\n",
        "                chunk_par_ids,\n",
        "                source='en',\n",
        "                target=language,\n",
        "                max_workers=5,\n",
        "                similarity_threshold=similarity_threshold\n",
        "            )\n",
        "\n",
        "            all_results_df = pd.concat([all_results_df, result_df])\n",
        "\n",
        "            # Save intermediate results\n",
        "            all_results_df.to_csv(f'data/backtrans_temp_{language}.csv', index=False)\n",
        "\n",
        "            # Optional: Add a delay between chunks\n",
        "            time.sleep(2)\n",
        "\n",
        "        # Save final results\n",
        "        all_results_df.to_csv(output_file, index=False)\n",
        "\n",
        "        # Print statistics\n",
        "        total = len(all_results_df)\n",
        "        augmented = all_results_df['is_augmented'].sum()\n",
        "        print(f\"Completed {language}: {total} samples processed\")\n",
        "        print(f\"Kept {augmented} samples ({augmented/total:.1%}) with similarity ≥ {similarity_threshold}\")\n",
        "        print(f\"Average similarity: {all_results_df['similarity'].mean():.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCa0qvJqVLpT"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mKaqTS0VLpT"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "lr = 1e-5\n",
        "n_epochs = 2\n",
        "betas = (0.9, 0.98)\n",
        "eps = 1e-6\n",
        "wd = 1e-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oXKJCEbVLpT"
      },
      "outputs": [],
      "source": [
        "class PCLDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, balance_method='oversample', seed=seed):\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "         # Split into positive and negative classes\n",
        "        pos_df = dataframe[dataframe['pcl_label'] == 1]\n",
        "        neg_df = dataframe[dataframe['pcl_label'] == 0]\n",
        "\n",
        "        # Balance classes\n",
        "        if balance_method == 'oversample':\n",
        "            # Repeat minority class samples\n",
        "            if len(pos_df) > len(neg_df):\n",
        "                pos_df, neg_df = neg_df, pos_df\n",
        "            n_samples = max(len(pos_df), len(neg_df))\n",
        "            pos_df = pos_df.sample(n_samples, replace=True, random_state=seed)\n",
        "        elif balance_method == 'undersample':\n",
        "            # Take minimum number of samples\n",
        "            n_samples = min(len(pos_df), len(neg_df))\n",
        "            pos_df = pos_df.sample(n_samples, random_state=seed)\n",
        "            neg_df = neg_df.sample(n_samples, random_state=seed)\n",
        "        elif balance_method == 'None':\n",
        "            pass\n",
        "\n",
        "        # Combine and shuffle\n",
        "        balanced_df = pd.concat([pos_df, neg_df]).sample(frac=1, random_state=seed)\n",
        "        self.texts = balanced_df['text'].tolist()\n",
        "        self.labels = balanced_df['pcl_label'].tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Initialize tokenizer and datasets\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"answerdotai/ModernBERT-base\")\n",
        "\n",
        "# Load all backtranslation files and combine them\n",
        "backtrans_files = [\n",
        "    'data/backtrans_data_de.csv',\n",
        "    # 'data/backtrans_data_es.csv',\n",
        "    'data/backtrans_data_fr.csv',\n",
        "    # 'data/backtrans_data_ru.csv',\n",
        "    'data/backtrans_data_zh-CN.csv'\n",
        "]\n",
        "\n",
        "backtrans_dfs = []\n",
        "for file in backtrans_files:\n",
        "    try:\n",
        "        cur_df = pd.read_csv(file)\n",
        "        backtrans_dfs.append(cur_df)\n",
        "        print(f\"Loaded {file} with {len(df)} rows\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {file}: {e}\")\n",
        "\n",
        "# Combine all backtranslation dataframes\n",
        "if backtrans_dfs:\n",
        "    backtrans_df = pd.concat(backtrans_dfs, ignore_index=True)\n",
        "    print(f\"Combined backtranslation data: {len(backtrans_df)} rows\")\n",
        "else:\n",
        "    backtrans_df = pd.DataFrame()\n",
        "    print(\"No backtranslation data found\")\n",
        "\n",
        "# Create datasets\n",
        "for col in train_df.columns:\n",
        "    if col not in backtrans_df.columns:\n",
        "        backtrans_df[col] = None\n",
        "\n",
        "backtrans_df = backtrans_df[train_df.columns]\n",
        "backtrans_df['pcl_label'] = backtrans_df['pcl_label'].astype(int)\n",
        "augmented_train_df = pd.concat([backtrans_df, train_df], ignore_index=True)\n",
        "print(augmented_train_df.head())\n",
        "train_dataset = PCLDataset(augmented_train_df, tokenizer)\n",
        "val_dataset = PCLDataset(val_df, tokenizer, balance_method='None')\n",
        "test_dataset = PCLDataset(test_df, tokenizer, balance_method='None')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ovyIzdKUGWq"
      },
      "source": [
        "## Weighted Random Sampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cozqcQtdUGWq"
      },
      "outputs": [],
      "source": [
        "class WeightedRandomSamplerTrainer(Trainer):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.weights = torch.FloatTensor(self._get_weights())\n",
        "        self.sampler = WeightedRandomSampler(self.weights, len(self.weights), replacement=True)\n",
        "\n",
        "    def get_train_dataloader(self):\n",
        "        return DataLoader(self.train_dataset, batch_size=self.args.train_batch_size, sampler=self.sampler, collate_fn=self.data_collator)\n",
        "\n",
        "    def _get_weights(self):\n",
        "        labels = np.array(self.train_dataset.labels)\n",
        "        class_counts = np.bincount(labels)\n",
        "        class_weights = 1.0 / np.sqrt(class_counts.astype(np.float32))\n",
        "        weights = class_weights[labels]\n",
        "        return weights\n",
        "\n",
        "train_dataset = PCLDataset(augmented_train_df, tokenizer, 'None')\n",
        "val_dataset = PCLDataset(val_df, tokenizer, balance_method='None')\n",
        "test_dataset = PCLDataset(test_df, tokenizer, balance_method='None')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBn4QsCRVLpT"
      },
      "outputs": [],
      "source": [
        "# reset_seeds()\n",
        "# model_config = AutoConfig.from_pretrained(\"answerdotai/ModernBERT-base\")\n",
        "# model_config.mlp_dropout = 0.2\n",
        "# model_config.num_labels = 2\n",
        "\n",
        "# # Initialize model with classification head\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(\n",
        "#     \"answerdotai/ModernBERT-base\",\n",
        "#     num_labels=2,\n",
        "# )\n",
        "# model.train()\n",
        "# Training setup\n",
        "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# print(\"Using device:\", device)\n",
        "# model.to(device)\n",
        "# training_args = TrainingArguments(\n",
        "#     seed=seed,\n",
        "#     data_seed=seed,\n",
        "#     dataloader_num_workers=0,\n",
        "#     output_dir=f\"ModernBERT_pcl_ft\",\n",
        "#     learning_rate=lr,\n",
        "#     per_device_train_batch_size=batch_size,\n",
        "#     per_device_eval_batch_size=batch_size,\n",
        "#     num_train_epochs=n_epochs,\n",
        "#     lr_scheduler_type=\"cosine\",\n",
        "#     optim=\"adamw_torch_fused\",\n",
        "#     adam_beta1=betas[0],\n",
        "#     adam_beta2=betas[1],\n",
        "#     adam_epsilon=eps,\n",
        "#     # weight_decay=wd,\n",
        "#     logging_strategy=\"epoch\",\n",
        "#     eval_strategy=\"epoch\",\n",
        "#     save_strategy=\"epoch\",\n",
        "#     load_best_model_at_end=True,\n",
        "#     bf16=True,\n",
        "#     bf16_full_eval=True,\n",
        "#     push_to_hub=False,\n",
        "#     warmup_ratio=0.1,\n",
        "#     full_determinism=True\n",
        "\n",
        "# )\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Calculate classification metrics for Hugging Face Trainer\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        labels, predictions, average='binary'\n",
        "    )\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "# class MetricsCallback(TrainerCallback):\n",
        "#     def __init__(self):\n",
        "#         self.training_history = {\"train\": [], \"eval\": []}\n",
        "\n",
        "#     def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "#         if logs is not None:\n",
        "#             if \"loss\" in logs:  # Training logs\n",
        "#                 self.training_history[\"train\"].append(logs)\n",
        "#             elif \"eval_loss\" in logs:  # Evaluation logs\n",
        "#                 self.training_history[\"eval\"].append(logs)\n",
        "\n",
        "\n",
        "\n",
        "class MetricsCallback(TrainerCallback):\n",
        "    def __init__(self):\n",
        "        self.training_history = {\"train\": [], \"eval\": []}\n",
        "        self.best_f1 = 0.0\n",
        "        self.best_epoch = 0\n",
        "        self.best_step = 0\n",
        "\n",
        "    def on_evaluate(self, args, state, control, metrics, **kwargs):\n",
        "        self.training_history[\"eval\"].append(metrics)\n",
        "        # Track best F1 score\n",
        "        if metrics.get(\"eval_f1\", 0) > self.best_f1:\n",
        "            self.best_f1 = metrics.get(\"eval_f1\", 0)\n",
        "            self.best_epoch = state.epoch\n",
        "            self.best_step = state.global_step\n",
        "\n",
        "    def on_log(self, args, state, control, logs, **kwargs):\n",
        "        if \"loss\" in logs:\n",
        "            self.training_history[\"train\"].append(logs)\n",
        "\n",
        "\n",
        "\n",
        "def train_model_with_seed(seed, model_name, train_dataset, val_dataset, output_dir):\n",
        "    reset_seeds(seed)\n",
        "\n",
        "    # Create a unique output directory for this seed\n",
        "    seed_output_dir = f\"{output_dir}/seed_{seed}\"\n",
        "    os.makedirs(seed_output_dir, exist_ok=True)\n",
        "\n",
        "    # Load model with seed-specific configuration\n",
        "    config = AutoConfig.from_pretrained(model_name, num_labels=2)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_name, config=config)\n",
        "\n",
        "    # Training arguments\n",
        "    training_args = TrainingArguments(\n",
        "      seed=seed,\n",
        "      data_seed=seed,\n",
        "      dataloader_num_workers=0,\n",
        "      output_dir=seed_output_dir,\n",
        "      learning_rate=lr,\n",
        "      per_device_train_batch_size=batch_size,\n",
        "      per_device_eval_batch_size=batch_size,\n",
        "      num_train_epochs=n_epochs,\n",
        "      lr_scheduler_type=\"cosine\",\n",
        "      optim=\"adamw_torch_fused\",\n",
        "      adam_beta1=betas[0],\n",
        "      adam_beta2=betas[1],\n",
        "      adam_epsilon=eps,\n",
        "      # weight_decay=wd,\n",
        "      logging_strategy=\"epoch\",\n",
        "      eval_strategy=\"epoch\",\n",
        "      save_strategy=\"epoch\",\n",
        "      load_best_model_at_end=True,\n",
        "      bf16=True,\n",
        "      bf16_full_eval=True,\n",
        "      push_to_hub=False,\n",
        "      warmup_ratio=0.1,\n",
        "      # full_determinism=True\n",
        "    )\n",
        "\n",
        "    # Initialize metrics callback\n",
        "    metrics_callback = MetricsCallback()\n",
        "\n",
        "    # Initialize trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        processing_class=tokenizer,\n",
        "        data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[metrics_callback],\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    print(f\"Training model with seed {seed}...\")\n",
        "    trainer.train()\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    eval_results = trainer.evaluate()\n",
        "\n",
        "    # Save the best model path and its metrics\n",
        "    best_checkpoint = os.path.join(seed_output_dir, f\"checkpoint-{metrics_callback.best_step}\")\n",
        "\n",
        "    return {\n",
        "        \"seed\": seed,\n",
        "        \"f1_score\": metrics_callback.best_f1,\n",
        "        \"best_checkpoint\": best_checkpoint,\n",
        "        \"eval_results\": eval_results,\n",
        "        \"best_epoch\": metrics_callback.best_epoch\n",
        "    }\n",
        "\n",
        "def predict_with_model(model_path, test_dataset, tokenizer=None):\n",
        "    \"\"\"Use Trainer.predict() to get predictions from a model checkpoint\"\"\"\n",
        "    # Load model and tokenizer from checkpoint\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "    if tokenizer is None:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "    # Create a temporary trainer for prediction\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./tmp_predict\",\n",
        "        per_device_eval_batch_size=32,\n",
        "        report_to=\"none\",\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        processing_class=tokenizer,\n",
        "        data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    # Get predictions\n",
        "    print(f\"Getting predictions from model at {model_path}\")\n",
        "    predictions = trainer.predict(test_dataset)\n",
        "\n",
        "    # Extract logits and convert to probabilities\n",
        "    logits = predictions.predictions\n",
        "    probs = F.softmax(torch.tensor(logits), dim=1).numpy()\n",
        "\n",
        "    # Get class predictions (0 or 1)\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "\n",
        "    return preds, probs\n",
        "\n",
        "def ensemble_predict(model_paths, test_dataset, tokenizer=None):\n",
        "    \"\"\"Combine predictions from multiple models using majority voting\"\"\"\n",
        "    all_predictions = []\n",
        "    all_probabilities = []\n",
        "\n",
        "    # Get predictions from each model\n",
        "    for model_path in model_paths:\n",
        "        preds, probs = predict_with_model(model_path, test_dataset, tokenizer)\n",
        "        all_predictions.append(preds)\n",
        "        all_probabilities.append(probs)\n",
        "\n",
        "    # Stack predictions for voting\n",
        "    stacked_preds = np.stack(all_predictions)\n",
        "\n",
        "    # Majority voting (mode of predictions)\n",
        "    voted_predictions = []\n",
        "    for i in range(len(test_dataset)):\n",
        "        votes = stacked_preds[:, i]\n",
        "        # Find most common prediction (0 or 1)\n",
        "        voted_pred = Counter(votes).most_common(1)[0][0]\n",
        "        voted_predictions.append(voted_pred)\n",
        "\n",
        "    # Average probabilities\n",
        "    avg_probs = np.mean(np.stack(all_probabilities), axis=0)\n",
        "\n",
        "    return np.array(voted_predictions), avg_probs\n",
        "\n",
        "def train_ensemble(model_name, train_dataset, val_dataset, test_dataset, num_models=10, output_dir=f\"ModernBERT_pcl_ft\"):\n",
        "    \"\"\"Train multiple models with different seeds and create an ensemble\"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Train multiple models with different seeds\n",
        "    model_results = []\n",
        "    seeds = list(range(42, 42 + num_models))  # Use seeds 42 to 51\n",
        "\n",
        "    for seed in seeds:\n",
        "        result = train_model_with_seed(seed, model_name, train_dataset, val_dataset, output_dir)\n",
        "        model_results.append(result)\n",
        "        print(f\"Seed {seed} - F1 Score: {result['f1_score']:.4f}\")\n",
        "\n",
        "    # Sort models by validation F1 score and select top 3\n",
        "    model_results.sort(key=lambda x: x['f1_score'], reverse=True)\n",
        "    top_models = model_results[:3]\n",
        "\n",
        "    print(\"\\nTop 3 models:\")\n",
        "    for i, model in enumerate(top_models):\n",
        "        print(f\"{i+1}. Seed {model['seed']} - F1 Score: {model['f1_score']:.4f}\")\n",
        "\n",
        "    # Get the checkpoint paths for the top models\n",
        "    top_model_paths = [model[\"best_checkpoint\"] for model in top_models]\n",
        "\n",
        "    # Save ensemble metadata\n",
        "    ensemble_info = {\n",
        "        \"models\": [{\"seed\": m[\"seed\"], \"checkpoint\": m[\"best_checkpoint\"], \"f1_score\": m[\"f1_score\"]} for m in top_models],\n",
        "        \"creation_date\": pd.Timestamp.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    }\n",
        "\n",
        "    pd.DataFrame(ensemble_info[\"models\"]).to_csv(f\"{output_dir}/ensemble_models.csv\", index=False)\n",
        "\n",
        "    # Evaluate ensemble on test set\n",
        "    print(\"\\nEvaluating ensemble on test set...\")\n",
        "    ensemble_preds, ensemble_probs = ensemble_predict(top_model_paths, test_dataset)\n",
        "\n",
        "    # Get true labels from test dataset\n",
        "    true_labels = [item['labels'].item() for item in test_dataset]\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(true_labels, ensemble_preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, ensemble_preds, average='binary')\n",
        "\n",
        "    print(f\"Ensemble Test Results:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "\n",
        "    # Compare with individual model performance\n",
        "    print(\"\\nComparing with individual model performance:\")\n",
        "    for i, model_path in enumerate(top_model_paths):\n",
        "        model_preds, _ = predict_with_model(model_path, test_dataset)\n",
        "        model_accuracy = accuracy_score(true_labels, model_preds)\n",
        "        model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(true_labels, model_preds, average='binary')\n",
        "\n",
        "        print(f\"Model {i+1} (Seed {top_models[i]['seed']}):\")\n",
        "        print(f\"  Accuracy: {model_accuracy:.4f}\")\n",
        "        print(f\"  F1 Score: {model_f1:.4f}\")\n",
        "        print(f\"  Precision: {model_precision:.4f}\")\n",
        "        print(f\"  Recall: {model_recall:.4f}\")\n",
        "\n",
        "    # Create a prediction function for future use\n",
        "    def predict_with_ensemble(new_dataset):\n",
        "        \"\"\"Function to make predictions with the ensemble on new data\"\"\"\n",
        "        return ensemble_predict(top_model_paths, new_dataset)\n",
        "\n",
        "    return top_model_paths, ensemble_preds, ensemble_probs, predict_with_ensemble\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# trainer = WeightedRandomSamplerTrainer(\n",
        "#     model=model,\n",
        "#     args=training_args,\n",
        "#     train_dataset=train_dataset,\n",
        "#     eval_dataset=val_dataset,\n",
        "#     processing_class=tokenizer,\n",
        "#     data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
        "#     compute_metrics=compute_metrics,\n",
        "# )\n",
        "\n",
        "# metrics_callback = MetricsCallback()\n",
        "# trainer.add_callback(metrics_callback)\n",
        "\n",
        "# trainer.train()\n",
        "\n",
        "# train_history_df = pd.DataFrame(metrics_callback.training_history[\"train\"])\n",
        "# train_history_df = train_history_df.add_prefix(\"train_\")\n",
        "# eval_history_df = pd.DataFrame(metrics_callback.training_history[\"eval\"])\n",
        "# train_res_df = pd.concat([train_history_df, eval_history_df], axis=1)\n",
        "\n",
        "# args_df = pd.DataFrame([training_args.to_dict()])\n",
        "\n",
        "# display(train_res_df)\n",
        "# display(args_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your model name\n",
        "model_name = \"answerdotai/ModernBERT-base\"  # or your preferred model\n",
        "\n",
        "# Train the ensemble\n",
        "top_model_paths, ensemble_preds, ensemble_probs, predict_fn = train_ensemble(\n",
        "    model_name=model_name,\n",
        "    train_dataset=train_dataset,\n",
        "    val_dataset=val_dataset,\n",
        "    test_dataset=test_dataset,\n",
        "    num_models=10,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "se4k2-CqlsZu",
        "outputId": "35a4cbc3-88c7-41da-c772-89c83660e29b"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All random states have been reset with seed 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with seed 42...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3350' max='3350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3350/3350 07:47, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.232200</td>\n",
              "      <td>0.210800</td>\n",
              "      <td>0.929552</td>\n",
              "      <td>0.593103</td>\n",
              "      <td>0.710744</td>\n",
              "      <td>0.508876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.082700</td>\n",
              "      <td>0.364934</td>\n",
              "      <td>0.922985</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.651515</td>\n",
              "      <td>0.508876</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [105/105 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed 42 - F1 Score: 0.5931\n",
            "All random states have been reset with seed 43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with seed 43...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3350' max='3350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3350/3350 07:47, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.222800</td>\n",
              "      <td>0.240387</td>\n",
              "      <td>0.925970</td>\n",
              "      <td>0.495935</td>\n",
              "      <td>0.792208</td>\n",
              "      <td>0.360947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.086100</td>\n",
              "      <td>0.376582</td>\n",
              "      <td>0.922388</td>\n",
              "      <td>0.551724</td>\n",
              "      <td>0.661157</td>\n",
              "      <td>0.473373</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [105/105 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed 43 - F1 Score: 0.5517\n",
            "All random states have been reset with seed 44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with seed 44...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3350' max='3350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3350/3350 07:41, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.222400</td>\n",
              "      <td>0.263775</td>\n",
              "      <td>0.924776</td>\n",
              "      <td>0.483607</td>\n",
              "      <td>0.786667</td>\n",
              "      <td>0.349112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.077900</td>\n",
              "      <td>0.363577</td>\n",
              "      <td>0.926567</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.694915</td>\n",
              "      <td>0.485207</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [105/105 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed 44 - F1 Score: 0.5714\n",
            "All random states have been reset with seed 45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with seed 45...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3350' max='3350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3350/3350 07:50, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.213300</td>\n",
              "      <td>0.312481</td>\n",
              "      <td>0.921194</td>\n",
              "      <td>0.410714</td>\n",
              "      <td>0.836364</td>\n",
              "      <td>0.272189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.077900</td>\n",
              "      <td>0.376597</td>\n",
              "      <td>0.918806</td>\n",
              "      <td>0.524476</td>\n",
              "      <td>0.641026</td>\n",
              "      <td>0.443787</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [105/105 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed 45 - F1 Score: 0.5245\n",
            "All random states have been reset with seed 46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with seed 46...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3350' max='3350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3350/3350 07:43, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.233200</td>\n",
              "      <td>0.264683</td>\n",
              "      <td>0.918806</td>\n",
              "      <td>0.546667</td>\n",
              "      <td>0.625954</td>\n",
              "      <td>0.485207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.095300</td>\n",
              "      <td>0.360710</td>\n",
              "      <td>0.920597</td>\n",
              "      <td>0.552189</td>\n",
              "      <td>0.640625</td>\n",
              "      <td>0.485207</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: an illegal memory access was encountered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-139-89c9b5965f8b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Train the ensemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m top_model_paths, ensemble_preds, ensemble_probs, predict_fn = train_ensemble(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-138-2abf4c63054b>\u001b[0m in \u001b[0;36mtrain_ensemble\u001b[0;34m(model_name, train_dataset, val_dataset, test_dataset, num_models, output_dir)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseeds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model_with_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0mmodel_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Seed {seed} - F1 Score: {result['f1_score']:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-138-2abf4c63054b>\u001b[0m in \u001b[0;36mtrain_model_with_seed\u001b[0;34m(seed, model_name, train_dataset, val_dataset, output_dir)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;31m# Evaluate on validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m     \u001b[0meval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;31m# Save the best model path and its metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4072\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4073\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   4074\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4075\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4287\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_across_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4288\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4289\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_across_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4290\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_logits_for_metrics\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4291\u001b[0m                     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_logits_for_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mpad_across_processes\u001b[0;34m(self, tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m   2598\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2599\u001b[0m         \"\"\"\n\u001b[0;32m-> 2600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpad_across_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2602\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0munwrap_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_fp32_wrapper\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_torch_compile\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDistributedOperationException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0moperation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{function.__module__}.{function.__name__}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mpad_across_processes\u001b[0;34m(tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     return recursively_apply(\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0m_pad_across_processes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_on_other_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m         )\n\u001b[1;32m    125\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtest_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0merror_on_other_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m_pad_across_processes\u001b[0;34m(tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# Gather all sizes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0msizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;31m# Then pad to the maximum size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKS9Ma6aVLpT"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO_h-VE7VLpT",
        "outputId": "c0ca6219-1156-4787-e9da-a86820af5186"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   par_id      art_id      topic country  \\\n",
            "0       1  @@24942188   hopeless      ph   \n",
            "1       2  @@21968160    migrant      gh   \n",
            "2       3  @@16584954  immigrant      ie   \n",
            "3       4   @@7811231   disabled      nz   \n",
            "4       5   @@1494111    refugee      ca   \n",
            "\n",
            "                                                text  label  \n",
            "0  We 're living in times of absolute insanity , ...      0  \n",
            "1  In Libya today , there are countless number of...      0  \n",
            "2  White House press secretary Sean Spicer said t...      0  \n",
            "3  Council customers only signs would be displaye...      0  \n",
            "4  \" Just like we received migrants fleeing El Sa...      0  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-90-ff13329d1276>:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(logits).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00977466, 0.9902254 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "checkpoint_path = \"./ModernBERT_pcl_ft/checkpoint-1676\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint_path)\n",
        "\n",
        "\n",
        "# Evaluation on a single example\n",
        "def predict_single(text: str, model, tokenizer, device='cuda'):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    encoding = tokenizer(\n",
        "        text,\n",
        "        max_length=512,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "\n",
        "    return F.softmax(logits).cpu().numpy()\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "test_input = df[df['label'] == 3]['text'].iloc[3]\n",
        "predict_single(test_input, model, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "Eizio0pSVLpU"
      },
      "outputs": [],
      "source": [
        "# from huggingface_hub import notebook_login\n",
        "\n",
        "# notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "B7IGhWHPyjpU"
      },
      "outputs": [],
      "source": [
        "# model_name = \"Hasasasaki/modernBERT_pcl_ft\"\n",
        "# model.push_to_hub(model_name)\n",
        "# tokenizer.push_to_hub(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "riUan1skzH_P",
        "outputId": "fc2b2f8a-d246-45bf-b0a2-74b9b2b5f96c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='131' max='131' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [131/131 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.34968075156211853,\n",
              " 'eval_model_preparation_time': 0.0058,\n",
              " 'eval_accuracy': 0.9144768275203058,\n",
              " 'eval_f1': 0.535064935064935,\n",
              " 'eval_precision': 0.553763440860215,\n",
              " 'eval_recall': 0.5175879396984925,\n",
              " 'eval_runtime': 7.1778,\n",
              " 'eval_samples_per_second': 291.592,\n",
              " 'eval_steps_per_second': 18.251}"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    processing_class=tokenizer,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "trainer.evaluate(test_dataset)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}