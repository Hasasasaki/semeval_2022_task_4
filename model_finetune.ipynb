{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hasasasaki/semeval_2022_task_4/blob/main/model_finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "4qHbOJcwcWcv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv_mP3i6UrPj",
        "outputId": "6a7e2e1b-733c-48c1-952b-66e8bc5c810a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deep_translator in /usr/local/lib/python3.11/dist-packages (1.11.4)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.11/dist-packages (from deep_translator) (4.13.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from deep_translator) (2.32.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "# !pip install \"flash_attn==2.6.3\" --no-build-isolation\n",
        "!pip install deep_translator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HglL0PQVLpR"
      },
      "source": [
        "## Data processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "4n7udvqWVLpS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74568909-72b8-486e-fb95-77540daa5ab5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All random states have been reset with seed 42\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    DataCollatorWithPadding,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    TrainerCallback,\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from collections import Counter\n",
        "\n",
        "seed = 42\n",
        "\n",
        "def reset_seeds(seed=seed):\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "    import numpy as np\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.use_deterministic_algorithms(True)\n",
        "\n",
        "    print(f\"All random states have been reset with seed {seed}\")\n",
        "\n",
        "reset_seeds()\n",
        "\n",
        "new_columns = [\n",
        "    \"par_id\",      # 1 (integer ID)\n",
        "    \"art_id\",      # @@24942188 (article identifier)\n",
        "    \"topic\",       # hopeless (PCL category)\n",
        "    \"country\",     # ph (country code)\n",
        "    \"text\",        # Full text content\n",
        "    \"label\"        # 0 (binary label)\n",
        "]\n",
        "\n",
        "# Read main dataset - skip 4 disclaimer rows\n",
        "df = pd.read_csv(\n",
        "    \"data/dontpatronizeme_pcl.tsv\",\n",
        "    sep=\"\\t\",\n",
        "    header=None,\n",
        "    skiprows=4,\n",
        "    names=new_columns,\n",
        "    on_bad_lines='warn'\n",
        ")\n",
        "\n",
        "# Read train/dev splits\n",
        "train_val_labels = pd.read_csv(\"data/train_semeval_parids-labels.csv\")\n",
        "test_labels = pd.read_csv(\"data/dev_semeval_parids-labels.csv\")\n",
        "\n",
        "# Convert string labels to lists\n",
        "def parse_labels(label_str: str) -> list[int]:\n",
        "    return [int(x) for x in label_str.strip(\"[]\").replace(\" \", \"\").split(\",\")]\n",
        "\n",
        "# Process labels dataframes\n",
        "for labels_df in [train_val_labels, test_labels]:\n",
        "    labels_df['labels'] = labels_df['label'].apply(parse_labels)\n",
        "    labels_df.drop('label', axis=1, inplace=True)\n",
        "\n",
        "# Join with main data\n",
        "train_val_df = df.merge(train_val_labels, on=\"par_id\", how=\"inner\")\n",
        "test_df = df.merge(test_labels, on=\"par_id\", how=\"inner\")\n",
        "\n",
        "# Add PCL positivity column to both dataframes\n",
        "train_val_df['pcl_label'] = train_val_df['label'].apply(\n",
        "    lambda x: 0 if x in {0, 1} else 1)\n",
        "test_df['pcl_label'] = test_df['label'].apply(\n",
        "    lambda x: 0 if x in {0, 1} else 1)\n",
        "\n",
        "train_df, val_df = train_test_split(train_val_df, test_size=0.2, random_state=42, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlPG3JxjUGWp",
        "outputId": "8c6573cb-57a4-47ba-f78e-4c21a8ecc9f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ],
      "source": [
        "import nltk\n",
        "# os.environ[\"TRANSFORMERS_CACHE\"] = \"/vol/bitbucket/bj321/.cache\"\n",
        "# nltk.data.path.append(\"/vol/bitbucket/bj321/nltk_data\")  # Your custom path\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSIrXlbcUGWp",
        "outputId": "660b0b31-5cf7-4ec4-a565-d3e130e015ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10823"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ],
      "source": [
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OzlLMoQUGWp",
        "outputId": "c0d00e19-bd7a-414c-d88c-f1d2bf6c1c03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading SentenceBERT model...\n"
          ]
        }
      ],
      "source": [
        "from deep_translator import GoogleTranslator\n",
        "import concurrent.futures\n",
        "import time\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# Load SentenceBERT model\n",
        "print(\"Loading SentenceBERT model...\")\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')  # Smaller, faster model\n",
        "# Alternative: model = SentenceTransformer('paraphrase-mpnet-base-v2')  # More accurate but slower\n",
        "\n",
        "def compute_similarity(original, translated):\n",
        "    \"\"\"Compute cosine similarity between original and translated text embeddings\"\"\"\n",
        "    # Get embeddings\n",
        "    emb1 = model.encode([original])[0]\n",
        "    emb2 = model.encode([translated])[0]\n",
        "\n",
        "    # Compute cosine similarity (1 - cosine distance)\n",
        "    similarity = 1 - cosine(emb1, emb2)\n",
        "    return similarity\n",
        "\n",
        "def back_translate_single(item):\n",
        "    \"\"\"Process a single text item with similarity filtering\"\"\"\n",
        "    text, label, par_id, source, target, idx, similarity_threshold = item\n",
        "    try:\n",
        "        # First translation (source to target)\n",
        "        translated = GoogleTranslator(source=source, target=target).translate(text)\n",
        "        time.sleep(0.5)  # Avoid rate limiting\n",
        "\n",
        "        # Second translation (target back to source)\n",
        "        back_translated = GoogleTranslator(source=target, target=source).translate(translated)\n",
        "\n",
        "        # Compute semantic similarity\n",
        "        similarity = compute_similarity(text, back_translated)\n",
        "\n",
        "        # Only return translations that maintain semantic similarity\n",
        "        if similarity >= similarity_threshold:\n",
        "            return back_translated, label, par_id, idx, similarity, True\n",
        "        else:\n",
        "            print(f\"Low similarity ({similarity:.3f}) for item {idx}: discarded\")\n",
        "            return text, label, par_id, idx, similarity, False  # Return original text but mark as not augmented\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in item {idx}: {str(e)}\")\n",
        "        return None, None, None, idx, 0.0, False\n",
        "\n",
        "def back_translate_batch(texts, labels, par_ids, source='en', target='zh-CN', max_workers=5, similarity_threshold=0.75):\n",
        "    \"\"\"Process texts in parallel batches with similarity filtering\"\"\"\n",
        "    results = [None] * len(texts)\n",
        "    labels_out = [None] * len(labels)\n",
        "    par_ids_out = [None] * len(par_ids)\n",
        "    similarities = [0.0] * len(texts)\n",
        "    is_augmented = [False] * len(texts)\n",
        "\n",
        "    # Create work items\n",
        "    work_items = [(texts[i], labels[i], par_ids[i], source, target, i, similarity_threshold) for i in range(len(texts))]\n",
        "\n",
        "    # Process in parallel\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        futures = [executor.submit(back_translate_single, item) for item in work_items]\n",
        "\n",
        "        # Process results as they complete\n",
        "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures)):\n",
        "            result, label, par_id, idx, similarity, augmented = future.result()\n",
        "            if result is not None:\n",
        "                results[idx] = result\n",
        "                labels_out[idx] = label\n",
        "                par_ids_out[idx] = par_id\n",
        "                similarities[idx] = similarity\n",
        "                is_augmented[idx] = augmented\n",
        "\n",
        "    # Create DataFrame with results\n",
        "    result_df = pd.DataFrame({\n",
        "        'par_id': par_ids_out,\n",
        "        'original_text': texts,\n",
        "        'text': results,\n",
        "        'pcl_label': [int(x) if x is not None else None for x in labels_out],\n",
        "        'similarity': similarities,\n",
        "        'is_augmented': is_augmented\n",
        "    })\n",
        "\n",
        "    # Filter out None values\n",
        "    result_df = result_df.dropna(subset=['text'])\n",
        "\n",
        "    return result_df\n",
        "\n",
        "# Main processing loop\n",
        "language_list = ['zh-CN', 'fr', 'ru']\n",
        "similarity_threshold = 0.75  # Adjust as needed\n",
        "\n",
        "for language in language_list:\n",
        "    output_file = f'data/backtrans_data_{language}.csv'\n",
        "\n",
        "    if not os.path.exists(output_file):\n",
        "        print(f\"Processing language: {language}\")\n",
        "\n",
        "        # Process in chunks to avoid memory issues\n",
        "        chunk_size = 100\n",
        "        all_results_df = pd.DataFrame()\n",
        "\n",
        "        for i in range(0, len(train_df), chunk_size):\n",
        "            chunk_texts = train_df['text'].iloc[i:i+chunk_size].tolist()\n",
        "            chunk_labels = train_df['pcl_label'].iloc[i:i+chunk_size].tolist()\n",
        "            chunk_par_ids = train_df['par_id'].iloc[i:i+chunk_size].tolist()\n",
        "\n",
        "            print(f\"Processing chunk {i//chunk_size + 1}/{len(train_df)//chunk_size + 1}\")\n",
        "            result_df = back_translate_batch(\n",
        "                chunk_texts,\n",
        "                chunk_labels,\n",
        "                chunk_par_ids,\n",
        "                source='en',\n",
        "                target=language,\n",
        "                max_workers=5,\n",
        "                similarity_threshold=similarity_threshold\n",
        "            )\n",
        "\n",
        "            all_results_df = pd.concat([all_results_df, result_df])\n",
        "\n",
        "            # Save intermediate results\n",
        "            all_results_df.to_csv(f'data/backtrans_temp_{language}.csv', index=False)\n",
        "\n",
        "            # Optional: Add a delay between chunks\n",
        "            time.sleep(2)\n",
        "\n",
        "        # Save final results\n",
        "        all_results_df.to_csv(output_file, index=False)\n",
        "\n",
        "        # Print statistics\n",
        "        total = len(all_results_df)\n",
        "        augmented = all_results_df['is_augmented'].sum()\n",
        "        print(f\"Completed {language}: {total} samples processed\")\n",
        "        print(f\"Kept {augmented} samples ({augmented/total:.1%}) with similarity â‰¥ {similarity_threshold}\")\n",
        "        print(f\"Average similarity: {all_results_df['similarity'].mean():.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCa0qvJqVLpT"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "-mKaqTS0VLpT"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "lr = 1e-5\n",
        "n_epochs = 2\n",
        "betas = (0.9, 0.98)\n",
        "eps = 1e-6\n",
        "wd = 1e-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oXKJCEbVLpT",
        "outputId": "b5a9a78a-130a-4088-86d9-547fa4450737"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded data/backtrans_data_zh-CN.csv with 10468 rows\n",
            "Combined backtranslation data: 6700 rows\n",
            "   par_id      art_id     topic country  \\\n",
            "0    5825   @@9438566   in-need      au   \n",
            "1    7171   @@1934487  hopeless      ng   \n",
            "2     680   @@9525972   in-need      nz   \n",
            "3    4906  @@22596758   refugee      bd   \n",
            "4    8180  @@13717053   migrant      ph   \n",
            "\n",
            "                                                text label labels  pcl_label  \n",
            "0  She described local police as resource and cri...  None   None          0  \n",
            "1  The only force that can stop them is below 99%...  None   None          1  \n",
            "2  Labour's agent education spokesman Grant Rober...  None   None          0  \n",
            "3  New figures show that more than 48,000 Rohingy...  None   None          0  \n",
            "4  He then listed several immigrants, mainly from...  None   None          0  \n"
          ]
        }
      ],
      "source": [
        "class PCLDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, balance_method='oversample', seed=seed):\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "         # Split into positive and negative classes\n",
        "        pos_df = dataframe[dataframe['pcl_label'] == 1]\n",
        "        neg_df = dataframe[dataframe['pcl_label'] == 0]\n",
        "\n",
        "        # Balance classes\n",
        "        if balance_method == 'oversample':\n",
        "            # Repeat minority class samples\n",
        "            if len(pos_df) > len(neg_df):\n",
        "                pos_df, neg_df = neg_df, pos_df\n",
        "            n_samples = max(len(pos_df), len(neg_df))\n",
        "            pos_df = pos_df.sample(n_samples, replace=True, random_state=seed)\n",
        "        elif balance_method == 'undersample':\n",
        "            # Take minimum number of samples\n",
        "            n_samples = min(len(pos_df), len(neg_df))\n",
        "            pos_df = pos_df.sample(n_samples, random_state=seed)\n",
        "            neg_df = neg_df.sample(n_samples, random_state=seed)\n",
        "        elif balance_method == 'None':\n",
        "            pass\n",
        "\n",
        "        # Combine and shuffle\n",
        "        balanced_df = pd.concat([pos_df, neg_df]).sample(frac=1, random_state=seed)\n",
        "        self.texts = balanced_df['text'].tolist()\n",
        "        self.labels = balanced_df['pcl_label'].tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Initialize tokenizer and datasets\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"answerdotai/ModernBERT-base\")\n",
        "\n",
        "# Load all backtranslation files and combine them\n",
        "backtrans_files = [\n",
        "    # 'data/backtrans_data_de.csv',\n",
        "    # 'data/backtrans_data_es.csv',\n",
        "    # 'data/backtrans_data_fr.csv',\n",
        "    # 'data/backtrans_data_ru.csv',\n",
        "    'data/backtrans_data_zh-CN.csv'\n",
        "]\n",
        "\n",
        "backtrans_dfs = []\n",
        "for file in backtrans_files:\n",
        "    try:\n",
        "        cur_df = pd.read_csv(file)\n",
        "        backtrans_dfs.append(cur_df)\n",
        "        print(f\"Loaded {file} with {len(df)} rows\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {file}: {e}\")\n",
        "\n",
        "# Combine all backtranslation dataframes\n",
        "if backtrans_dfs:\n",
        "    backtrans_df = pd.concat(backtrans_dfs, ignore_index=True)\n",
        "    print(f\"Combined backtranslation data: {len(backtrans_df)} rows\")\n",
        "else:\n",
        "    backtrans_df = pd.DataFrame()\n",
        "    print(\"No backtranslation data found\")\n",
        "\n",
        "# Create datasets\n",
        "for col in train_df.columns:\n",
        "    if col not in backtrans_df.columns:\n",
        "        backtrans_df[col] = None\n",
        "\n",
        "backtrans_df = backtrans_df[train_df.columns]\n",
        "backtrans_df['pcl_label'] = backtrans_df['pcl_label'].astype(int)\n",
        "augmented_train_df = pd.concat([backtrans_df, train_df], ignore_index=True)\n",
        "print(augmented_train_df.head())\n",
        "train_dataset = PCLDataset(augmented_train_df, tokenizer)\n",
        "val_dataset = PCLDataset(val_df, tokenizer, balance_method='None')\n",
        "test_dataset = PCLDataset(test_df, tokenizer, balance_method='None')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ovyIzdKUGWq"
      },
      "source": [
        "## Weighted Random Sampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "cozqcQtdUGWq"
      },
      "outputs": [],
      "source": [
        "class WeightedRandomSamplerTrainer(Trainer):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.weights = torch.FloatTensor(self._get_weights())\n",
        "        self.sampler = WeightedRandomSampler(self.weights, len(self.weights), replacement=True)\n",
        "\n",
        "    def get_train_dataloader(self):\n",
        "        return DataLoader(self.train_dataset, batch_size=self.args.train_batch_size, sampler=self.sampler, collate_fn=self.data_collator)\n",
        "\n",
        "    def _get_weights(self):\n",
        "        labels = np.array(self.train_dataset.labels)\n",
        "        class_counts = np.bincount(labels)\n",
        "        class_weights = 1.0 / np.sqrt(class_counts.astype(np.float32))\n",
        "        weights = class_weights[labels]\n",
        "        return weights\n",
        "\n",
        "train_dataset = PCLDataset(augmented_train_df, tokenizer, 'None')\n",
        "val_dataset = PCLDataset(val_df, tokenizer, balance_method='None')\n",
        "test_dataset = PCLDataset(test_df, tokenizer, balance_method='None')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "aBn4QsCRVLpT"
      },
      "outputs": [],
      "source": [
        "# reset_seeds()\n",
        "# model_config = AutoConfig.from_pretrained(\"answerdotai/ModernBERT-base\")\n",
        "# model_config.mlp_dropout = 0.2\n",
        "# model_config.num_labels = 2\n",
        "\n",
        "# # Initialize model with classification head\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(\n",
        "#     \"answerdotai/ModernBERT-base\",\n",
        "#     num_labels=2,\n",
        "# )\n",
        "# model.train()\n",
        "# Training setup\n",
        "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# print(\"Using device:\", device)\n",
        "# model.to(device)\n",
        "# training_args = TrainingArguments(\n",
        "#     seed=seed,\n",
        "#     data_seed=seed,\n",
        "#     dataloader_num_workers=0,\n",
        "#     output_dir=f\"ModernBERT_pcl_ft\",\n",
        "#     learning_rate=lr,\n",
        "#     per_device_train_batch_size=batch_size,\n",
        "#     per_device_eval_batch_size=batch_size,\n",
        "#     num_train_epochs=n_epochs,\n",
        "#     lr_scheduler_type=\"cosine\",\n",
        "#     optim=\"adamw_torch_fused\",\n",
        "#     adam_beta1=betas[0],\n",
        "#     adam_beta2=betas[1],\n",
        "#     adam_epsilon=eps,\n",
        "#     # weight_decay=wd,\n",
        "#     logging_strategy=\"epoch\",\n",
        "#     eval_strategy=\"epoch\",\n",
        "#     save_strategy=\"epoch\",\n",
        "#     load_best_model_at_end=True,\n",
        "#     bf16=True,\n",
        "#     bf16_full_eval=True,\n",
        "#     push_to_hub=False,\n",
        "#     warmup_ratio=0.1,\n",
        "#     full_determinism=True\n",
        "\n",
        "# )\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Calculate classification metrics for Hugging Face Trainer\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        labels, predictions, average='binary'\n",
        "    )\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "# class MetricsCallback(TrainerCallback):\n",
        "#     def __init__(self):\n",
        "#         self.training_history = {\"train\": [], \"eval\": []}\n",
        "\n",
        "#     def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "#         if logs is not None:\n",
        "#             if \"loss\" in logs:  # Training logs\n",
        "#                 self.training_history[\"train\"].append(logs)\n",
        "#             elif \"eval_loss\" in logs:  # Evaluation logs\n",
        "#                 self.training_history[\"eval\"].append(logs)\n",
        "\n",
        "\n",
        "\n",
        "class MetricsCallback(TrainerCallback):\n",
        "    def __init__(self):\n",
        "        self.training_history = {\"train\": [], \"eval\": []}\n",
        "        self.best_f1 = 0.0\n",
        "        self.best_epoch = 0\n",
        "        self.best_step = 0\n",
        "\n",
        "    def on_evaluate(self, args, state, control, metrics, **kwargs):\n",
        "        self.training_history[\"eval\"].append(metrics)\n",
        "        # Track best F1 score\n",
        "        if metrics.get(\"eval_f1\", 0) > self.best_f1:\n",
        "            self.best_f1 = metrics.get(\"eval_f1\", 0)\n",
        "            self.best_epoch = state.epoch\n",
        "            self.best_step = state.global_step\n",
        "\n",
        "    def on_log(self, args, state, control, logs, **kwargs):\n",
        "        if \"loss\" in logs:\n",
        "            self.training_history[\"train\"].append(logs)\n",
        "\n",
        "\n",
        "\n",
        "def train_model_with_seed(seed, model_name, train_dataset, val_dataset, output_dir):\n",
        "    reset_seeds(seed)\n",
        "\n",
        "    # Create a unique output directory for this seed\n",
        "    seed_output_dir = f\"{output_dir}/seed_{seed}\"\n",
        "    os.makedirs(seed_output_dir, exist_ok=True)\n",
        "\n",
        "    # Load model with seed-specific configuration\n",
        "    config = AutoConfig.from_pretrained(model_name, num_labels=2)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_name, config=config)\n",
        "\n",
        "    # Training arguments\n",
        "    training_args = TrainingArguments(\n",
        "      seed=seed,\n",
        "      data_seed=seed,\n",
        "      dataloader_num_workers=0,\n",
        "      output_dir=seed_output_dir,\n",
        "      learning_rate=lr,\n",
        "      per_device_train_batch_size=batch_size,\n",
        "      per_device_eval_batch_size=batch_size,\n",
        "      num_train_epochs=n_epochs,\n",
        "      lr_scheduler_type=\"cosine\",\n",
        "      optim=\"adamw_torch_fused\",\n",
        "      adam_beta1=betas[0],\n",
        "      adam_beta2=betas[1],\n",
        "      adam_epsilon=eps,\n",
        "      # weight_decay=wd,\n",
        "      logging_strategy=\"epoch\",\n",
        "      eval_strategy=\"epoch\",\n",
        "      save_strategy=\"epoch\",\n",
        "      load_best_model_at_end=True,\n",
        "      bf16=True,\n",
        "      bf16_full_eval=True,\n",
        "      push_to_hub=False,\n",
        "      warmup_ratio=0.1,\n",
        "      full_determinism=True\n",
        "    )\n",
        "\n",
        "    # Initialize metrics callback\n",
        "    metrics_callback = MetricsCallback()\n",
        "\n",
        "    # Initialize trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        processing_class=tokenizer,\n",
        "        data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[metrics_callback],\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    print(f\"Training model with seed {seed}...\")\n",
        "    trainer.train()\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    eval_results = trainer.evaluate()\n",
        "\n",
        "    # Save the best model path and its metrics\n",
        "    best_checkpoint = os.path.join(seed_output_dir, f\"checkpoint-{metrics_callback.best_step}\")\n",
        "\n",
        "    return {\n",
        "        \"seed\": seed,\n",
        "        \"f1_score\": metrics_callback.best_f1,\n",
        "        \"best_checkpoint\": best_checkpoint,\n",
        "        \"eval_results\": eval_results,\n",
        "        \"best_epoch\": metrics_callback.best_epoch\n",
        "    }\n",
        "\n",
        "def predict_with_model(model_path, test_dataset, tokenizer=None):\n",
        "    \"\"\"Use Trainer.predict() to get predictions from a model checkpoint\"\"\"\n",
        "    # Load model and tokenizer from checkpoint\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "    if tokenizer is None:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "    # Create a temporary trainer for prediction\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./tmp_predict\",\n",
        "        per_device_eval_batch_size=32,\n",
        "        report_to=\"none\",\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        processing_class=tokenizer,\n",
        "        data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    # Get predictions\n",
        "    print(f\"Getting predictions from model at {model_path}\")\n",
        "    predictions = trainer.predict(test_dataset)\n",
        "\n",
        "    # Extract logits and convert to probabilities\n",
        "    logits = predictions.predictions\n",
        "    probs = F.softmax(torch.tensor(logits), dim=1).numpy()\n",
        "\n",
        "    # Get class predictions (0 or 1)\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "\n",
        "    return preds, probs\n",
        "\n",
        "def ensemble_predict(model_paths, test_dataset, tokenizer=None):\n",
        "    \"\"\"Combine predictions from multiple models using majority voting\"\"\"\n",
        "    all_predictions = []\n",
        "    all_probabilities = []\n",
        "\n",
        "    # Get predictions from each model\n",
        "    for model_path in model_paths:\n",
        "        preds, probs = predict_with_model(model_path, test_dataset, tokenizer)\n",
        "        all_predictions.append(preds)\n",
        "        all_probabilities.append(probs)\n",
        "\n",
        "    # Stack predictions for voting\n",
        "    stacked_preds = np.stack(all_predictions)\n",
        "\n",
        "    # Majority voting (mode of predictions)\n",
        "    voted_predictions = []\n",
        "    for i in range(len(test_dataset)):\n",
        "        votes = stacked_preds[:, i]\n",
        "        # Find most common prediction (0 or 1)\n",
        "        voted_pred = Counter(votes).most_common(1)[0][0]\n",
        "        voted_predictions.append(voted_pred)\n",
        "\n",
        "    # Average probabilities\n",
        "    avg_probs = np.mean(np.stack(all_probabilities), axis=0)\n",
        "\n",
        "    return np.array(voted_predictions), avg_probs\n",
        "\n",
        "def train_ensemble(model_name, train_dataset, val_dataset, test_dataset, num_models=10, output_dir=f\"ModernBERT_pcl_ft\"):\n",
        "    \"\"\"Train multiple models with different seeds and create an ensemble\"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Train multiple models with different seeds\n",
        "    model_results = []\n",
        "    seeds = list(range(42, 42 + num_models))  # Use seeds 42 to 51\n",
        "\n",
        "    for seed in seeds:\n",
        "        result = train_model_with_seed(seed, model_name, train_dataset, val_dataset, output_dir)\n",
        "        model_results.append(result)\n",
        "        print(f\"Seed {seed} - F1 Score: {result['f1_score']:.4f}\")\n",
        "\n",
        "    # Sort models by validation F1 score and select top 3\n",
        "    model_results.sort(key=lambda x: x['f1_score'], reverse=True)\n",
        "    top_models = model_results[:3]\n",
        "\n",
        "    print(\"\\nTop 3 models:\")\n",
        "    for i, model in enumerate(top_models):\n",
        "        print(f\"{i+1}. Seed {model['seed']} - F1 Score: {model['f1_score']:.4f}\")\n",
        "\n",
        "    # Get the checkpoint paths for the top models\n",
        "    top_model_paths = [model[\"best_checkpoint\"] for model in top_models]\n",
        "\n",
        "    # Save ensemble metadata\n",
        "    ensemble_info = {\n",
        "        \"models\": [{\"seed\": m[\"seed\"], \"checkpoint\": m[\"best_checkpoint\"], \"f1_score\": m[\"f1_score\"]} for m in top_models],\n",
        "        \"creation_date\": pd.Timestamp.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    }\n",
        "\n",
        "    pd.DataFrame(ensemble_info[\"models\"]).to_csv(f\"{output_dir}/ensemble_models.csv\", index=False)\n",
        "\n",
        "    # Evaluate ensemble on test set\n",
        "    print(\"\\nEvaluating ensemble on test set...\")\n",
        "    ensemble_preds, ensemble_probs = ensemble_predict(top_model_paths, test_dataset)\n",
        "\n",
        "    # Get true labels from test dataset\n",
        "    true_labels = [item['labels'].item() for item in test_dataset]\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(true_labels, ensemble_preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, ensemble_preds, average='binary')\n",
        "\n",
        "    print(f\"Ensemble Test Results:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "\n",
        "    # Compare with individual model performance\n",
        "    print(\"\\nComparing with individual model performance:\")\n",
        "    for i, model_path in enumerate(top_model_paths):\n",
        "        model_preds, _ = predict_with_model(model_path, test_dataset)\n",
        "        model_accuracy = accuracy_score(true_labels, model_preds)\n",
        "        model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(true_labels, model_preds, average='binary')\n",
        "\n",
        "        print(f\"Model {i+1} (Seed {top_models[i]['seed']}):\")\n",
        "        print(f\"  Accuracy: {model_accuracy:.4f}\")\n",
        "        print(f\"  F1 Score: {model_f1:.4f}\")\n",
        "        print(f\"  Precision: {model_precision:.4f}\")\n",
        "        print(f\"  Recall: {model_recall:.4f}\")\n",
        "\n",
        "    # Create a prediction function for future use\n",
        "    def predict_with_ensemble(new_dataset):\n",
        "        \"\"\"Function to make predictions with the ensemble on new data\"\"\"\n",
        "        return ensemble_predict(top_model_paths, new_dataset)\n",
        "\n",
        "    return top_model_paths, ensemble_preds, ensemble_probs, predict_with_ensemble\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# trainer = WeightedRandomSamplerTrainer(\n",
        "#     model=model,\n",
        "#     args=training_args,\n",
        "#     train_dataset=train_dataset,\n",
        "#     eval_dataset=val_dataset,\n",
        "#     processing_class=tokenizer,\n",
        "#     data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
        "#     compute_metrics=compute_metrics,\n",
        "# )\n",
        "\n",
        "# metrics_callback = MetricsCallback()\n",
        "# trainer.add_callback(metrics_callback)\n",
        "\n",
        "# trainer.train()\n",
        "\n",
        "# train_history_df = pd.DataFrame(metrics_callback.training_history[\"train\"])\n",
        "# train_history_df = train_history_df.add_prefix(\"train_\")\n",
        "# eval_history_df = pd.DataFrame(metrics_callback.training_history[\"eval\"])\n",
        "# train_res_df = pd.concat([train_history_df, eval_history_df], axis=1)\n",
        "\n",
        "# args_df = pd.DataFrame([training_args.to_dict()])\n",
        "\n",
        "# display(train_res_df)\n",
        "# display(args_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your model name\n",
        "model_name = \"answerdotai/ModernBERT-base\"  # or your preferred model\n",
        "\n",
        "# Train the ensemble\n",
        "top_model_paths, ensemble_preds, ensemble_probs, predict_fn = train_ensemble(\n",
        "    model_name=model_name,\n",
        "    train_dataset=train_dataset,\n",
        "    val_dataset=val_dataset,\n",
        "    test_dataset=test_dataset,\n",
        "    num_models=3,\n",
        ")"
      ],
      "metadata": {
        "id": "se4k2-CqlsZu",
        "outputId": "5141e618-c75d-4c07-aa3c-f8d9517d584c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All random states have been reset with seed 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-127-3809ec940d8f>:136: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with seed 42...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1676' max='1676' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1676/1676 04:08, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.264300</td>\n",
              "      <td>0.218494</td>\n",
              "      <td>0.921791</td>\n",
              "      <td>0.505660</td>\n",
              "      <td>0.697917</td>\n",
              "      <td>0.396450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.143500</td>\n",
              "      <td>0.236172</td>\n",
              "      <td>0.922985</td>\n",
              "      <td>0.553633</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.473373</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [105/105 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed 42 - F1 Score: 0.5536\n",
            "All random states have been reset with seed 43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-127-3809ec940d8f>:136: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with seed 43...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1676' max='1676' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1676/1676 04:10, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.250400</td>\n",
              "      <td>0.225110</td>\n",
              "      <td>0.921194</td>\n",
              "      <td>0.525180</td>\n",
              "      <td>0.669725</td>\n",
              "      <td>0.431953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.165800</td>\n",
              "      <td>0.252899</td>\n",
              "      <td>0.921791</td>\n",
              "      <td>0.520147</td>\n",
              "      <td>0.682692</td>\n",
              "      <td>0.420118</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [105/105 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed 43 - F1 Score: 0.5252\n",
            "All random states have been reset with seed 44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-127-3809ec940d8f>:136: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with seed 44...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1676' max='1676' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1676/1676 04:07, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.248900</td>\n",
              "      <td>0.208272</td>\n",
              "      <td>0.920000</td>\n",
              "      <td>0.496241</td>\n",
              "      <td>0.680412</td>\n",
              "      <td>0.390533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.147100</td>\n",
              "      <td>0.244687</td>\n",
              "      <td>0.918209</td>\n",
              "      <td>0.541806</td>\n",
              "      <td>0.623077</td>\n",
              "      <td>0.479290</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [105/105 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed 44 - F1 Score: 0.5418\n",
            "\n",
            "Top 3 models:\n",
            "1. Seed 42 - F1 Score: 0.5536\n",
            "2. Seed 44 - F1 Score: 0.5418\n",
            "3. Seed 43 - F1 Score: 0.5252\n",
            "\n",
            "Evaluating ensemble on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-127-3809ec940d8f>:179: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting predictions from model at ModernBERT_pcl_ft/seed_42/checkpoint-1676\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-127-3809ec940d8f>:179: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting predictions from model at ModernBERT_pcl_ft/seed_44/checkpoint-1676\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-127-3809ec940d8f>:179: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting predictions from model at ModernBERT_pcl_ft/seed_43/checkpoint-838\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Test Results:\n",
            "Accuracy: 0.9221\n",
            "F1 Score: 0.5015\n",
            "Precision: 0.6406\n",
            "Recall: 0.4121\n",
            "\n",
            "Comparing with individual model performance:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-127-3809ec940d8f>:179: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting predictions from model at ModernBERT_pcl_ft/seed_42/checkpoint-1676\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 1 (Seed 42):\n",
            "  Accuracy: 0.9202\n",
            "  F1 Score: 0.5045\n",
            "  Precision: 0.6159\n",
            "  Recall: 0.4271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-127-3809ec940d8f>:179: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting predictions from model at ModernBERT_pcl_ft/seed_44/checkpoint-1676\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 2 (Seed 44):\n",
            "  Accuracy: 0.9226\n",
            "  F1 Score: 0.5235\n",
            "  Precision: 0.6312\n",
            "  Recall: 0.4472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-127-3809ec940d8f>:179: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting predictions from model at ModernBERT_pcl_ft/seed_43/checkpoint-838\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 3 (Seed 43):\n",
            "  Accuracy: 0.9178\n",
            "  F1 Score: 0.4788\n",
            "  Precision: 0.6031\n",
            "  Recall: 0.3970\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKS9Ma6aVLpT"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO_h-VE7VLpT",
        "outputId": "c0ca6219-1156-4787-e9da-a86820af5186"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   par_id      art_id      topic country  \\\n",
            "0       1  @@24942188   hopeless      ph   \n",
            "1       2  @@21968160    migrant      gh   \n",
            "2       3  @@16584954  immigrant      ie   \n",
            "3       4   @@7811231   disabled      nz   \n",
            "4       5   @@1494111    refugee      ca   \n",
            "\n",
            "                                                text  label  \n",
            "0  We 're living in times of absolute insanity , ...      0  \n",
            "1  In Libya today , there are countless number of...      0  \n",
            "2  White House press secretary Sean Spicer said t...      0  \n",
            "3  Council customers only signs would be displaye...      0  \n",
            "4  \" Just like we received migrants fleeing El Sa...      0  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-90-ff13329d1276>:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(logits).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00977466, 0.9902254 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "checkpoint_path = \"./ModernBERT_pcl_ft/checkpoint-1676\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint_path)\n",
        "\n",
        "\n",
        "# Evaluation on a single example\n",
        "def predict_single(text: str, model, tokenizer, device='cuda'):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    encoding = tokenizer(\n",
        "        text,\n",
        "        max_length=512,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "\n",
        "    return F.softmax(logits).cpu().numpy()\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "test_input = df[df['label'] == 3]['text'].iloc[3]\n",
        "predict_single(test_input, model, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "Eizio0pSVLpU"
      },
      "outputs": [],
      "source": [
        "# from huggingface_hub import notebook_login\n",
        "\n",
        "# notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "B7IGhWHPyjpU"
      },
      "outputs": [],
      "source": [
        "# model_name = \"Hasasasaki/modernBERT_pcl_ft\"\n",
        "# model.push_to_hub(model_name)\n",
        "# tokenizer.push_to_hub(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "riUan1skzH_P",
        "outputId": "fc2b2f8a-d246-45bf-b0a2-74b9b2b5f96c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='131' max='131' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [131/131 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.34968075156211853,\n",
              " 'eval_model_preparation_time': 0.0058,\n",
              " 'eval_accuracy': 0.9144768275203058,\n",
              " 'eval_f1': 0.535064935064935,\n",
              " 'eval_precision': 0.553763440860215,\n",
              " 'eval_recall': 0.5175879396984925,\n",
              " 'eval_runtime': 7.1778,\n",
              " 'eval_samples_per_second': 291.592,\n",
              " 'eval_steps_per_second': 18.251}"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    processing_class=tokenizer,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "trainer.evaluate(test_dataset)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}